<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>International Workshop on Agentic AI for Clinical Decision-Making in Medical Imaging (ACDMI)</title>
  <link rel="stylesheet" href="style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet" />
</head>
<body>
  <!-- Header / Navigation -->
  <header>
    <div class="container">
      <nav>
        <ul>
          <li><a href="#home">Home</a></li>
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#aims">Aims and Scope</a></li>
          <li><a href="#topics">Workshop Topics</a></li>
          <li><a href="#rationale">Rationale</a></li>
          <li><a href="#committee">Committee</a></li>
          <li><a href="#format">Workshop Format</a></li>
          <li><a href="#events">Related Previous Events</a></li>
          <li><a href="#biographies">Biographies</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <!-- Home Section with Kinkaku-ji Temple Image -->
  <section id="home">
    <div class="hero-image">
      <img src="Naples.jpg" alt="Image: Georges Jansoone, CC BY-SA 3.0, via Wikimedia Commons}" />
      <div class="hero-text">
        <h1> International Workshop on Agentic AI for Clinical Decision-Making in Medical Imaging (ACDMI)</h1>
        <p> A workshop at the 2026 European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD) </p>
      </div>
    </div>
  </section>

  <!-- Abstract Section -->
  <section id="abstract">
    <div class="container">
      <h2>Abstract</h2>
      <p>
Agentic artificial intelligence refers to systems capable of autonomous, goal-directed behavior and structured reasoning. It is emerging as a transformative paradigm for medical image analysis and clinical workflows. Unlike conventional predictive models that function in a passive, task-specific manner, agentic AI can actively interact with imaging platforms, access and integrate external knowledge sources, iteratively refine analytical outputs, and recommend context-aware actions to support diagnostic or interventional decision-making. Nevertheless, the deployment of such systems in high-stakes clinical environments introduces significant challenges, including maintaining robust perception under distributional shifts, ensuring adherence to physical and physiological constraints, providing transparent and interpretable multi-step reasoning processes, and aligning system behavior with established clinical guidelines, regulatory standards, and patient safety requirements.

This workshop focuses on machine learning methodologies that enable the design, training, and evaluation of agentic AI systems for medical imaging and broader clinical applications. We highlight approaches that integrate perception, reasoning, and decision-making into unified frameworks, including vision–language models for radiology report generation, reinforcement learning for adaptive imaging protocols, and AI agents that collaborate with human clinicians via interactive interfaces. Topics of interest include multi-modal representation learning, tool-augmented large language models, memory-augmented architectures, self-supervised pretraining on hospital data streams, and uncertainty-aware planning under partial observability.

A central theme of this research topic is the human–AI partnership. We explore how agentic systems can be designed to explain their actions, respect clinical workflows, and defer appropriately to human expertise. Particular attention is given to evaluation methodologies that go beyond task-specific accuracy to measure safety, trustworthiness, and clinical utility in realistic simulation environments and prospective studies.

By bringing together researchers from machine learning, computer vision, clinical informatics, radiology, and interventional medicine, this workshop aims to catalyze the development of next-generation AI systems that do not merely detect abnormalities, but actively assist, reason, and adapt alongside medical professionals in the pursuit of better patient outcomes.      </p>
    </div>
  </section>

 

  <!-- Workshop Topics Section -->
  <section id="topics">
    <div class="container">
      <h2>Workshop Topics</h2>
      <p>This half-day workshop focuses on machine learning methodologies that enable the design, development, and deployment of agentic AI systems for clinical decision-making, with a particular emphasis on medical imaging and associated workflows. While grounded in the concrete challenges of radiology, pathology, and interventional medicine, where decisions are time-critical, multi-modal, and tightly bound to patient safety, the workshop highlights a broader vision of \textbf{Agentic Clinical AI}: systems that not only perceive and predict, but also reason, act, and adapt in collaboration with human clinicians.

We aim to bring together researchers from machine learning, computer vision, biomedical informatics, clinical AI, and regulatory science to explore how autonomous agents can move beyond static prediction toward dynamic, goal-driven behavior in clinical environments. This is why we belive that ECML-PKDD is a perfect venue to host this workshop. A central objective is to foster cross-pollination between medical imaging, natural language processing, reinforcement learning, and human–computer interaction, as agentic systems inherently require integration across these disciplines. Key themes include interactive vision–language models for report generation and decision support, reinforcement learning for adaptive imaging protocols and treatment planning, and tool-augmented agents that query electronic health records, literature, or imaging databases in real time. Equally important are the challenges of safety, interpretability, and human alignment: how can we design agents that explain their reasoning, respect clinical workflows, and know when to defer to human expertise?

By emphasizing learning paradigms that enable robust performance under distribution shift, sparse feedback, and high-stakes uncertainty, the workshop aims to accelerate the translation of agentic AI from research prototypes to clinically validated systems that meaningfully augment diagnostic accuracy, operational efficiency, and patient care.

We invite contributions that introduce novel problem formulations, propose innovative agent architectures, or report on empirical studies of agentic systems deployed in simulated or real clinical environments. Submissions that highlight interdisciplinary collaboration, human-in-the-loop design, rigorous evaluation protocols, or explainability and trustworthiness in medical agents are particularly encouraged. In particular, we welcome contributions addressing, but not limited to:</p>
      <ul>
        <li>Agent Architectures for Clinical Decision-Making</li>
        <ul>
          <li> Vision–language agents for interactive radiology report generation and image interpretation </li>
          <li> Tool-augmented agents that query electronic health records, literature, and knowledge bases </li>
          <li> Memory-augmented architectures for maintaining clinical context across encounters </li>
          <li> Reinforcement learning and planning for adaptive imaging protocols and interventional guidance </li>
          <li> Multi-modal representation learning unifying imaging, text, and structured clinical data </li>
        </ul>
        <li> Human-AI Collaboration and Shared Autonomy </li>
        <ul> 
          <li> Systems that adaptively involve clinicians and maintain shared situational awareness </li>
          <li> Explainability and interpretability of multi-step agent reasoning in clinical terms </li>
          <li> Trustworthy deferral: when and how agents should hand over control to human experts </li>
          <li> Workflow integration and user interface design for collaborative AI systems </li>
          <li> Personalization of agent behavior to individual clinician preferences and practice styles </li>
        </ul>
        <li> Learning Paradigms for Agentic Medical AI </li>
        <ul> 
          <li> Self-supervised and multi-modal pretraining on large-scale hospital data streams </li>
          <li> Few-shot and continual learning for adapting agents to new modalities, sites, or rare conditions </li>
          <li> Simulation-based training using realistic clinical simulators and digital twins </li>
          <li> Imitation learning from clinician demonstrations and retrospective care trajectories </li>
          <li> ctive learning and adaptive data acquisition for agent refinement </li>
        </ul>
        <li> Safety, Robustness, and Clinical Alignment </li>
        <ul>
          <li> Formal verification and testing of agent behavior under distribution shift and adversarial inputs </li>
          <li> Uncertainty quantification and calibrated confidence for high-stakes decisions </li>
          <li> Alignment of agent objectives with clinical guidelines, safety constraints, and ethical norms </li>
          <li> Robustness to sensor noise, missing data, and out-of-distribution imaging findings </li>
          <li> Mitigating bias and ensuring fairness in agent-driven clinical workflows </li>
        </ul>
        <li> Evaluation Frameworks and Deployment Challenges </li>
        <ul> 
          <li> Realistic simulation environments for training and validating clinical agents </li>
          <li> Metrics for measuring clinical utility, trust, workflow efficiency, and patient outcomes </li>
          <li> Prospective study design and regulatory pathways for agentic AI systems </li>
          <li> Human factors evaluation and usability testing in clinical settings </li>
          <li> Case studies of deployed or prototyped agentic systems in radiology, pathology, or intervention </li>
        </ul>
        <li> Emerging Applications and Use Cases </li>
        <ul>
          <li> Autonomous or semi-autonomous image acquisition and protocol optimization </li>
          <li> Interactive decision support for differential diagnosis and treatment planning </li>
          <li> Agents for intra-operative guidance and robotic-assisted intervention </li>
          <li> Longitudinal patient monitoring and adaptive screening recommendations </li>
          <li> Multi-agent systems coordinating across specialties and care teams </li>
        </ul>
      </ul>
    </div>
  </section>

  <!-- Rationale Section -->
  <section id="rationale">
    <div class="container">
      <h2>Rationale</h2>
      <p>
        This special session addresses the pressing challenges posed by limited data availability in the medical imaging field, a critical area of research that directly impacts healthcare outcomes. The novelty of this session lies in its focus on innovative methodologies that leverage small datasets, including advanced techniques such as few-shot learning, uncertainty quantification, and the application of large language models (LLMs).
      </p>
      <p>
        As the demand for effective diagnostic tools continues to grow, the relevance of this session to the ADMA community is paramount. By fostering discussions on cutting-edge approaches and real-world applications, we aim to bridge the gap between theoretical advancements and practical implementations in healthcare. This session not only highlights the significance of data-driven solutions in medical imaging but also encourages collaboration and knowledge sharing among researchers, practitioners, and industry leaders.
      </p>
      <p>
        In a rapidly evolving technological landscape, the insights gained from this session will equip ADMA2025 attendees with the tools and strategies necessary to navigate the complexities of data scarcity, ultimately enhancing the quality and accessibility of medical imaging solutions.
      </p>
    </div>
  </section>

  <!-- Committee Section -->
  <section id="committee">
    <div class="container">
      <h2>Committee</h2>
      <h3>Organizing Committee</h3>
      <ul>
        <li>Essam A. Rashed, University of Hyogo, Japan – <a href="mailto:rashed@gsis.u-hyogo.ac.jp">rashed@gsis.u-hyogo.ac.jp</a> (<a href="https://erashed.weebly.com/">Homepage</a>)</li>
        <li>Alaa Tharwat, Bielefeld University of Applied Sciences and Arts (HSBI), Germany – <a href="mailto:alaa.othman@hsbi.de">alaa.othman@hsbi.de</a> (<a href="https://www.hsbi.de/personenverzeichnis/alaa-othman">Homepage</a>)</li>
      </ul>
      <h3>Technical Program Committee</h3>
      <ul>
        <li>Tarek Gaber, University of Salford, UK</li>
        <li>Muhammad Nouman, University of Hyogo, Japan</li>
        <li>Ahmed Elboardy, University of Hyogo, Japan</li>
        <li>Mahmoud Bekhit, Australian Catholic University, Australia</li>
        <li>Ghada Khoriba, Nile University, Egypt</li>
        <li>Syed Ahmad Chan Bukhari, St. John’s University, USA</li>
        <li>Dina Elmanakhly, Suez Canal University, Egypt</li>
        <li>Haytham Ali, University of Tsukuba, Japan</li>
        <li>Mona Selim, Suez University, Egypt</li>
        <li>Syed Shamsul Islam, Edith Cowan University, Australia</li>
      </ul>
    </div>
  </section>

  <!-- Workshop Format Section -->
  <section id="format">
    <div class="container">
      <h2>Workshop Format</h2>
      <p>
        We estimate the number of submissions to be between 10 and 15. Papers should not exceed 15 pages in LNAI format. All submissions will undergo a single-blind peer-review process. Authors are required to designate a speaker upon submission. Each presentation will include significant discussion time, and we will encourage authors to prepare questions to stimulate interaction, either right after their talk or during a panel session. These components aim to create an engaging and collaborative atmosphere for exchanging ideas and promoting active dialogue in the context of small data in medical imaging.
      </p>
    </div>
  </section>

  <!-- Related Previous Events Section -->
  <section id="events">
    <div class="container">
      <h2>Related Previous Events</h2>
      <p>This workshop builds on previous workshops, challenges, and tutorials that we have (co-)organized. We briefly list the most related ones:</p>
      <ul>
        <li>
          <strong>Interactive Adaptive Learning Workshop & Tutorial at ECML PKDD 2024.</strong> Organizers: M. Bunse, M. Herde, G. Krempl, V. Lemaire, M. T. Pham, A. Saadallah, and <strong>A. Tharwat</strong>. [8 accepted papers]<br>
          This tutorial consisted of two parts, an introduction to uncertainty-based active learning and a hands-on session on pool-based active learning with scikit-activeml and error-prone annotators.
        </li>
        <li>
          <strong>Learning from Small Data: Techniques and Applications Special session & Tutorial at the International Joint Conference on Neural Networks (IJCNN 2024), held in Yokohama, Japan.</strong> Organizers: <strong>T. Gaber</strong>, B. Hammer, M. Kohlhase, W. Schenck, <strong>A. Tharwat</strong>. [34 accepted papers/70 received papers]<br>
          This tutorial, titled 'Comprehensive Tutorial on Active Learning: Strategies and Applications,' focused on hands-on activities related to active learning and explored the uncertainty quantification methods used in this context.
        </li>
        <li>
          <strong>Interactive Adaptive Learning Workshop & Tutorial at ECML PKDD 2023.</strong> Organizers: M. Bunse, B. Hammer, V. Lemaire, G. Krempl, <strong>A. Tharwat</strong>, and A. Saadallah. [8 accepted papers]<br>
          This tutorial was focused on providing an overview on the literature and challenges beyond active labeling scenarios.
        </li>
      </ul>
    </div>
  </section>

  <!-- Biographies Section -->
  <section id="biographies">
    <div class="container">
      <h2>Biographies of the Organizers</h2>
      <h3>Essam A. Rashed</h3>
      <p>
        Essam A. Rashed received his Ph.D. (Eng.) in Computer Science from the University of Tsukuba, Japan in 2010. He was a JSPS Research Fellow at the University of Tsukuba (2010-2012). He served as Assistant/Associate/Full Professor of Computer Science at the Department of Mathematics, Faculty of Science, Suez Canal University from 2010. He was a research Professor at Nagoya Institute of Technology, Japan (2018-2021). Currently, he is a Professor at the Graduate School of Information Science, University of Hyogo, Japan. His research interests include medical image processing, data science, artificial intelligence and pattern recognition. Dr. Rashed is IEEE Senior Member and Associate Editor of the IEEE Access. In 2024, he was a recipient of the Commendation for Science and Technology by the Minister of Education, Culture, Sports, Science and Technology (Development Category), Japan. He participated as a PI and CoI for several external funded projects. (Webpage: <a href="https://erashed.weebly.com/">https://erashed.weebly.com/</a>)
      </p>
      <h3>Alaa Tharwat</h3>
      <p>
        Alaa Tharwat is a PostDoc and Research Group Leader at Bielefeld University of Applied Sciences and Arts, Bielefeld, Germany. He received his Ph.D. in Electrical Engineering from the Department of Electrical Engineering, Faculty of Engineering, Ain Shams University, Egypt. His main research interests include machine learning with small data, active learning, and optimization for Industry 4.0 applications. He has participated as a PC member in several conferences, including AISI held in Cairo, Egypt. Additionally, he has organized multiple workshops, special sessions, and tutorials at ECML PKDD in 2023 and 2024, as well as at IJCNN in 2024. (Webpage: <a href="https://www.hsbi.de/personenverzeichnis/alaa-othman">https://www.hsbi.de/personenverzeichnis/alaa-othman</a>)
      </p>
    </div>
  </section>

  <!-- Contact Section -->
  <section id="contact">
    <div class="container">
      <h2>Contact</h2>
      <p>
        For further details, please contact the organizing committee at <a href="mailto:rashed@gsis.u-hyogo.ac.jp">rashed@gsis.u-hyogo.ac.jp</a>.
      </p>
    </div>
  </section>

  <!-- Footer -->
  <footer>
    <div class="container">
      <p>© 2025 Learning from Small Data in Medical Imaging. All rights reserved.</p>
    </div>
  </footer>
</body>
</html>
